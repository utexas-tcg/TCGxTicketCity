{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary packages for models and querieng"
      ],
      "metadata": {
        "id": "VkGFBnq226SC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eZ6D2ifa4kVc"
      },
      "outputs": [],
      "source": [
        "#Import Packages\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "from google import genai\n",
        "import pandas as pd\n",
        "import os\n",
        "from google import genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authenticate and Connect the Google Query database"
      ],
      "metadata": {
        "id": "Z7XClhxo3DEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s99pUyVL4nPa",
        "outputId": "cde7b2e3-e151-45cc-b5bd-c5d7f355ad5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ],
      "source": [
        "#Authenticate and Connect to the Data\n",
        "\n",
        "os.environ['USE_AUTH_EPHEM'] = '0'  #Bypass the special permissions error from before\n",
        "\n",
        "# Authenticate to Google Cloud\n",
        "auth.authenticate_user()\n",
        "project_id = 'ticketcity-tcg' # Replace with your project ID\n",
        "client = bigquery.Client(project=project_id) # This line is added to create the client object\n",
        "print('Authenticated')\n",
        "\n",
        "\n",
        "project_id = 'ticketcity-tcg'\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "# Replace with your project ID and dataset/table names.\n",
        "# dataset_id = ''\n",
        "table_id = 'data-ticketcity.TC_Data.InventoryStream'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This SQL query extracts recent event-level ticketing data from the TicketCity dataset, focusing on events reported in the last seven days. It includes detailed information on event timing, location, sales performance, revenue, and ticket pricing, as well as metadata about the main performer. The query also calculates how many days in advance tickets were purchased, enabling analysis of consumer behavior and event demand trends."
      ],
      "metadata": {
        "id": "8SlDLXEK4Ws-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Fa5YqwOG4tL3"
      },
      "outputs": [],
      "source": [
        "# Create a SQL query string for our data.\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "    e.PID AS EventID,\n",
        "    e.Name AS EventName,\n",
        "    -- Convert \"MM/DD/YY hh:mm AM/PM\" format to proper TIMESTAMP\n",
        "    TIMESTAMP(PARSE_TIMESTAMP(\"%m/%d/%y %I:%M %p\", e.Date)) AS EventDateTime,\n",
        "    e.Venue,\n",
        "    e.City,\n",
        "    e.State,\n",
        "    e.Event_Type,\n",
        "    e.Category,\n",
        "    e.Orders,\n",
        "    e.Quantity as TotalEventTickets,\n",
        "    e.Avg_Order_Size as Order_Price,\n",
        "    e.Revenue,\n",
        "    ROUND(SAFE_DIVIDE(e.Revenue, e.Quantity), 2) AS Ticket_Price,  -- New column: Ticket Price\n",
        "    e.Report_Date as Date_Of_Purchase,\n",
        "    DATE_DIFF(\n",
        "       DATE(TIMESTAMP(PARSE_TIMESTAMP(\"%m/%d/%y %I:%M %p\", e.Date))),\n",
        "       e.Report_Date,\n",
        "       DAY\n",
        "    ) AS DaysBetweenPurchaseAndEvent,\n",
        "    pe.Performer_Name,\n",
        "    ep.Master\n",
        "FROM `data-ticketcity.TFS_Reports.75_Event_Daily` e\n",
        "LEFT JOIN `data-ticketcity.VividIntake.EventPerformers` ep\n",
        "    ON e.PID = ep.Event_ID\n",
        "    AND TIMESTAMP_TRUNC(ep._PARTITIONTIME, DAY) = TIMESTAMP(\"2025-03-01\")\n",
        "LEFT JOIN `data-ticketcity.VividIntake.Performers` pe\n",
        "    ON ep.Performer_ID = pe.Performer_ID\n",
        "    AND TIMESTAMP_TRUNC(pe._PARTITIONTIME, DAY) = TIMESTAMP(\"2025-03-01\")\n",
        "WHERE\n",
        "    e.Report_Date >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)\n",
        "    AND e.PID IS NOT NULL\n",
        "    AND e.Name IS NOT NULL\n",
        "    AND e.Date IS NOT NULL\n",
        "    AND e.Revenue IS NOT NULL\n",
        "    AND e.Avg_Order_Size IS NOT NULL\n",
        "    AND e.Orders IS NOT NULL\n",
        "    AND e.Quantity IS NOT NULL\n",
        "    AND e.Category != 'Parking'\n",
        "    AND (ep.Master IS NULL OR ep.Master = TRUE)\n",
        "ORDER BY e.Report_Date ASC;\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "18hE_7oe4xa7"
      },
      "outputs": [],
      "source": [
        "# Run the query\n",
        "#Name, Prefromer Name, City State, Venue, Category\n",
        "query_job = client.query(query)\n",
        "results = query_job.result()  # Fetch results again\n",
        "# Convert query results into a list of dictionaries\n",
        "data = [dict(row) for row in results]\n",
        "\n",
        "# Convert the list into a DataFrame\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the generative-AI prompt, we wanted to utilize information about the event's name, the artisit preforming, the city and state that they're preforming in, the venue that they are preforming at, and the type of preformance. We create a new dataframe to store this information."
      ],
      "metadata": {
        "id": "-65QB57V2foo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oxN_Sgcq5PVf"
      },
      "outputs": [],
      "source": [
        "selected_df = df[[\"EventName\", \"Performer_Name\", \"City\", \"State\", \"Venue\", \"Category\"]]\n",
        "\n",
        "selected_df = selected_df.head(1)\n",
        "\n",
        "formatted_info = \"\\n\".join([\n",
        "    f\"{row['EventName']} | {row['Performer_Name']} | {row['City']}, {row['State']} | {row['Venue']} | {row['Category']}\"\n",
        "    for _, row in selected_df.iterrows()\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the Gemini API, we created a function that takes the dataframe and the row number of the data that we want to generate a summary for. At the bottom, we call the function on the first three rows and the output shows that result."
      ],
      "metadata": {
        "id": "hQdgKghR5AaN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE64gpaI3ncn",
        "outputId": "522371c5-65c9-42af-ddcb-a46219744268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get ready for a night of classic American fun as the Bowling Green Hot Rods roll into Aberdeen to face off against the Ironbirds! This Minor League Baseball showdown takes place at the iconic Ripken Stadium in Aberdeen, Maryland, promising an evening packed with exciting plays, family-friendly entertainment, and the thrill of the game. Experience the energy of rising stars chasing their Major League dreams, all within the intimate setting of a ballpark designed to bring you closer to the action. Whether you're a die-hard baseball fan or just looking for a memorable night out, this game offers a perfect blend of sporting competition and community spirit under the lights at Ripken Stadium. Don't miss your chance to cheer on your team and enjoy America's favorite pastime!\n",
            "Summary added for row 0.\n",
            "Prepare to be amazed as Theresa Caputo, the renowned Long Island Medium, brings her extraordinary gift to the Abilene Auditorium in Abilene, TX. This isn't just a public speaking engagement; it's a captivating experience where Theresa connects with loved ones on the other side, delivering healing messages and providing comfort to audience members. Held within the classic and intimate setting of the Abilene Auditorium, this event promises an evening of heartfelt connections and undeniable proof that our loved ones are always with us. Don't miss this opportunity to witness Theresa's incredible ability firsthand and experience an unforgettable night of hope and healing.\n",
            "Summary added for row 1.\n",
            "Step back in time to December 4, 1956, and witness history unfold with \"Million Dollar Quartet\" at the historic Barter Theatre's intimate Gilliam Stage in Abingdon, VA. This isn't just a musical; it's a fly-on-the-wall experience of an iconic jam session. Feel the energy as four legends – Elvis Presley, Johnny Cash, Jerry Lee Lewis, and Carl Perkins – unexpectedly converge for one unforgettable night. Held within the charming confines of the Barter Theatre, renowned for its rich history and connection to the local community, this performance promises an up-close and personal encounter with the music that defined a generation. \"Million Dollar Quartet\" delivers a vibrant portrayal of rock 'n' roll's early days, complete with electrifying performances and a captivating storyline that will leave you singing along long after the curtain falls. It's a must-see for music lovers and history buffs alike, all within the welcoming atmosphere of a cherished theatrical landmark.\n",
            "Summary added for row 2.\n",
            "Saved to results_with_ai_summary.csv\n"
          ]
        }
      ],
      "source": [
        "# Configure Gemini\n",
        "client = genai.Client(api_key=\"\")\n",
        "\n",
        "def generate_ai_summary_for_row(df, row_num):\n",
        "    if row_num >= len(df):\n",
        "        print(f\"Row {row_num} is out of bounds.\")\n",
        "        return\n",
        "\n",
        "    row = df.loc[row_num]\n",
        "\n",
        "    formatted_info = f\"{row['EventName']} | {row['Performer_Name']} | {row['City']}, {row['State']} | {row['Venue']} | {row['Category']}\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert event sales analyst.\n",
        "\n",
        "    Given the following structured event data, write a **detailed and engaging description** that captures the essence of the event.\n",
        "    Focus on highlighting what makes it unique, such as the performers, location, and type of venue. Make it informative and concise. Format in paragraph form.\n",
        "\n",
        "    Event Info:\n",
        "    {formatted_info}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            contents=prompt\n",
        "        )\n",
        "        summary = response.text.strip()\n",
        "        print(summary)\n",
        "        df.loc[row_num, \"generated_summary_ai\"] = summary\n",
        "        print(f\"Summary added for row {row_num}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating summary for row {row_num}: {e}\")\n",
        "        df.loc[row_num, \"generated_summary_ai\"] = \"AI generation failed\"\n",
        "\n",
        "\n",
        "# Example: Call this multiple times to populate different rows\n",
        "generate_ai_summary_for_row(df, 0)\n",
        "generate_ai_summary_for_row(df, 1)\n",
        "generate_ai_summary_for_row(df, 2)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"results_with_ai_summary.csv\", index=False)\n",
        "print(\"Saved to results_with_ai_summary.csv\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}